{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70436353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"telemonitoring_parkinsons_updrs.data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21d12c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['subject#', 'age', 'sex', 'test_time', 'total_UPDRS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a48ef1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(columns=['motor_UPDRS'])\n",
    "target = df['motor_UPDRS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d37f8f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_normalized = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6321c80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jitter(%)         0.009890\n",
      "Jitter(Abs)       0.000070\n",
      "Jitter:RAP        0.006200\n",
      "Jitter:PPQ5       0.004190\n",
      "Jitter:DDP        0.018600\n",
      "Shimmer           0.041390\n",
      "Shimmer(dB)       0.329000\n",
      "Shimmer:APQ3      0.024940\n",
      "Shimmer:APQ5      0.020160\n",
      "Shimmer:APQ11     0.026790\n",
      "Shimmer:DDA       0.074810\n",
      "NHR               0.049333\n",
      "HNR              23.543000\n",
      "RPDE              0.493150\n",
      "DFA               0.644720\n",
      "PPE               0.143890\n",
      "Name: 5366, dtype: float64\n",
      "33.084\n",
      "18.177449390632482\n",
      "Mean Squared Error: 58.97586482228757\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the regression model\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "print(X_test.iloc[0])  # Use .iloc to access the first row of the DataFrame\n",
    "print(y_test.iloc[0])  # Use .iloc to access the first value of the Series\n",
    "print(y_pred[0])       # Access the first value of the numpy array\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b403301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de31737d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 229.2688 - mae: 12.3971 - val_loss: 85.7475 - val_mae: 7.6881\n",
      "Epoch 2/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 86.6303 - mae: 7.7178 - val_loss: 68.5146 - val_mae: 6.9839\n",
      "Epoch 3/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.1474 - mae: 7.0714 - val_loss: 65.8273 - val_mae: 6.8618\n",
      "Epoch 4/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70.6957 - mae: 7.0998 - val_loss: 66.8089 - val_mae: 6.8128\n",
      "Epoch 5/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.0106 - mae: 7.1363 - val_loss: 65.0619 - val_mae: 6.7781\n",
      "Epoch 6/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68.3156 - mae: 7.0080 - val_loss: 64.7685 - val_mae: 6.7602\n",
      "Epoch 7/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.1051 - mae: 7.0091 - val_loss: 66.1084 - val_mae: 6.8948\n",
      "Epoch 8/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67.6615 - mae: 6.9647 - val_loss: 72.6540 - val_mae: 6.9324\n",
      "Epoch 9/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71.5146 - mae: 7.1084 - val_loss: 63.6288 - val_mae: 6.7381\n",
      "Epoch 10/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67.6095 - mae: 6.9652 - val_loss: 66.4747 - val_mae: 6.9082\n",
      "Epoch 11/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69.0871 - mae: 7.0338 - val_loss: 65.5126 - val_mae: 6.7290\n",
      "Epoch 12/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67.3450 - mae: 6.9668 - val_loss: 63.2050 - val_mae: 6.7177\n",
      "Epoch 13/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68.9020 - mae: 7.0106 - val_loss: 65.3233 - val_mae: 6.8578\n",
      "Epoch 14/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68.9086 - mae: 7.0492 - val_loss: 62.9780 - val_mae: 6.7281\n",
      "Epoch 15/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.8026 - mae: 6.9567 - val_loss: 62.9466 - val_mae: 6.7309\n",
      "Epoch 16/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67.4227 - mae: 6.9994 - val_loss: 63.0010 - val_mae: 6.7340\n",
      "Epoch 17/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68.3500 - mae: 7.0323 - val_loss: 63.2753 - val_mae: 6.6645\n",
      "Epoch 18/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.1218 - mae: 6.9857 - val_loss: 64.6879 - val_mae: 6.8295\n",
      "Epoch 19/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.5057 - mae: 6.9837 - val_loss: 63.1568 - val_mae: 6.6797\n",
      "Epoch 20/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.0156 - mae: 6.9614 - val_loss: 62.3800 - val_mae: 6.6561\n",
      "Epoch 21/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.9267 - mae: 6.9660 - val_loss: 62.8774 - val_mae: 6.7407\n",
      "Epoch 22/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.0428 - mae: 6.8763 - val_loss: 62.3465 - val_mae: 6.6872\n",
      "Epoch 23/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.1513 - mae: 6.9149 - val_loss: 64.7916 - val_mae: 6.8288\n",
      "Epoch 24/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.3965 - mae: 6.9758 - val_loss: 61.8675 - val_mae: 6.6376\n",
      "Epoch 25/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.6426 - mae: 6.8943 - val_loss: 62.1814 - val_mae: 6.7021\n",
      "Epoch 26/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.6124 - mae: 6.9809 - val_loss: 63.1748 - val_mae: 6.7605\n",
      "Epoch 27/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.7053 - mae: 6.8264 - val_loss: 62.0321 - val_mae: 6.6909\n",
      "Epoch 28/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.0399 - mae: 6.8404 - val_loss: 61.9950 - val_mae: 6.6875\n",
      "Epoch 29/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.4986 - mae: 6.8681 - val_loss: 61.4863 - val_mae: 6.6348\n",
      "Epoch 30/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.9469 - mae: 6.9328 - val_loss: 62.5369 - val_mae: 6.6148\n",
      "Epoch 31/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.5566 - mae: 6.9302 - val_loss: 61.3084 - val_mae: 6.5991\n",
      "Epoch 32/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.8617 - mae: 6.9939 - val_loss: 61.1087 - val_mae: 6.6221\n",
      "Epoch 33/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.9751 - mae: 6.8591 - val_loss: 66.9336 - val_mae: 6.9231\n",
      "Epoch 34/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.9553 - mae: 6.7945 - val_loss: 63.0982 - val_mae: 6.6508\n",
      "Epoch 35/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.4526 - mae: 6.9406 - val_loss: 66.8049 - val_mae: 6.9208\n",
      "Epoch 36/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.2343 - mae: 6.9326 - val_loss: 60.7691 - val_mae: 6.6008\n",
      "Epoch 37/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.4161 - mae: 6.8283 - val_loss: 63.3455 - val_mae: 6.7578\n",
      "Epoch 38/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.0750 - mae: 6.8535 - val_loss: 61.3011 - val_mae: 6.6589\n",
      "Epoch 39/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.2500 - mae: 6.9112 - val_loss: 61.0836 - val_mae: 6.6496\n",
      "Epoch 40/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.4268 - mae: 6.8316 - val_loss: 61.0412 - val_mae: 6.6503\n",
      "Epoch 41/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.3175 - mae: 6.9549 - val_loss: 61.5855 - val_mae: 6.6780\n",
      "Epoch 42/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.0043 - mae: 6.7900 - val_loss: 60.4617 - val_mae: 6.6146\n",
      "Epoch 43/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.2345 - mae: 6.8577 - val_loss: 64.2900 - val_mae: 6.5987\n",
      "Epoch 44/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.8682 - mae: 6.8054 - val_loss: 59.9241 - val_mae: 6.5470\n",
      "Epoch 45/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.1687 - mae: 6.8538 - val_loss: 59.8554 - val_mae: 6.5286\n",
      "Epoch 46/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.9881 - mae: 6.7837 - val_loss: 60.5583 - val_mae: 6.5094\n",
      "Epoch 47/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 66.1024 - mae: 6.8696 - val_loss: 60.9038 - val_mae: 6.5021\n",
      "Epoch 48/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.5245 - mae: 6.9610 - val_loss: 59.8397 - val_mae: 6.5228\n",
      "Epoch 49/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.1015 - mae: 6.9350 - val_loss: 59.8594 - val_mae: 6.5190\n",
      "Epoch 50/50\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.3308 - mae: 6.7221 - val_loss: 59.5331 - val_mae: 6.5371\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58.7960 - mae: 6.5473 \n",
      "Test MAE: 6.63197135925293\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),  # Input layer\n",
    "    Dense(128, activation='relu'),  # Second hidden layer, change 182 to a more typical value\n",
    "    Dense(32, activation='relu'),  # Third hidden layer\n",
    "    Dense(1, activation='linear')  # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Early stopping to prevent overfitting (optional)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test MAE: {test_mae}\")\n",
    "\n",
    "# Predictions\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0d85f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0377\n",
      "39.511\n"
     ]
    }
   ],
   "source": [
    "print(min(target))\n",
    "print(max(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2934c585",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (167,) (168,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 67\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     66\u001b[0m audio_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamir.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 67\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(features)\n",
      "Cell \u001b[1;32mIn[22], line 16\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(audio_file)\u001b[0m\n\u001b[0;32m     14\u001b[0m jitter_abs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(f0)\n\u001b[0;32m     15\u001b[0m jitter_rap \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(np\u001b[38;5;241m.\u001b[39mdiff(f0)) \u001b[38;5;241m/\u001b[39m f0[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(f0) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 16\u001b[0m jitter_ppq5 \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf0\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(f0) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     17\u001b[0m jitter_ddp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(np\u001b[38;5;241m.\u001b[39mabs(np\u001b[38;5;241m.\u001b[39mdiff(f0))) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(f0) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# --- Shimmer Features ---\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Shimmer calculations require amplitude variation\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# We can use librosa's amplitude envelope estimation\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (167,) (168,) "
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(audio_file):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_file)\n",
    "\n",
    "    # --- Jitter Features ---\n",
    "    # Jitter: percentage, absolute, RAP, PPQ5, DDP\n",
    "    # Calculate fundamental frequency (F0) using librosa's pitch detection\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(y, fmin=librosa.note_to_hz('C1'), fmax=librosa.note_to_hz('C8'))\n",
    "\n",
    "    jitter_percent = (np.std(f0) / np.mean(f0) * 100) if np.mean(f0) != 0 else 0\n",
    "    jitter_abs = np.std(f0)\n",
    "    jitter_rap = (np.mean(np.abs(np.diff(f0)) / f0[:-1])) if len(f0) > 1 else 0\n",
    "    jitter_ppq5 = (np.mean(np.abs(np.diff(f0)) / np.concatenate(([f0[0]], f0[:-1])))) if len(f0) > 1 else 0\n",
    "    jitter_ddp = np.max(np.abs(np.diff(f0))) if len(f0) > 1 else 0\n",
    "\n",
    "    # --- Shimmer Features ---\n",
    "    # Shimmer calculations require amplitude variation\n",
    "    # We can use librosa's amplitude envelope estimation\n",
    "    amplitude_envelope = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "    \n",
    "    shimmer = (np.std(amplitude_envelope) / np.mean(amplitude_envelope)) if np.mean(amplitude_envelope) != 0 else 0\n",
    "    shimmer_db = (20 * np.log10(np.std(amplitude_envelope))) if np.std(amplitude_envelope) > 0 else 0\n",
    "    shimmer_apq3 = (np.mean(np.abs(np.diff(amplitude_envelope)) / amplitude_envelope[:-1])) if len(amplitude_envelope) > 1 else 0\n",
    "    shimmer_apq5 = (np.mean(np.abs(np.diff(amplitude_envelope)) / np.concatenate(([amplitude_envelope[0]], amplitude_envelope[:-1])))) if len(amplitude_envelope) > 1 else 0\n",
    "    shimmer_apq11 = (np.mean(np.abs(np.diff(amplitude_envelope)) / np.concatenate(([amplitude_envelope[0]], amplitude_envelope[:-1])))) if len(amplitude_envelope) > 1 else 0\n",
    "    shimmer_dda = (np.mean(np.abs(np.diff(amplitude_envelope)) / amplitude_envelope[:-1])) if len(amplitude_envelope) > 1 else 0\n",
    "\n",
    "    # --- Noise-to-Harmonics Ratio (NHR) and Harmonics-to-Noise Ratio (HNR) ---\n",
    "    # NHR and HNR measure the ratio of harmonics to noise in the signal\n",
    "    # librosa can help calculate the spectral flatness to estimate noise ratio\n",
    "    spectral_flatness = librosa.feature.spectral_flatness(y=y)\n",
    "    nhr = np.mean(spectral_flatness)\n",
    "    hnr = 1 / (1 + nhr)  # Inverse of NHR (simplified assumption)\n",
    "\n",
    "    # --- Nonlinear Features (RPDE, DFA, PPE) ---\n",
    "    # RPDE, DFA, and PPE are typically more advanced and are usually extracted using specialized libraries\n",
    "    # These would require custom calculations or usage of specialized libraries like pyAudioAnalysis or pyWorld\n",
    "    rpde = np.random.random()  # Placeholder: Calculate RPDE here if needed\n",
    "    dfa = np.random.random()    # Placeholder: Calculate DFA here if needed\n",
    "    ppe = np.random.random()   # Placeholder: Calculate PPE here if needed\n",
    "\n",
    "    # Return features as a dictionary\n",
    "    return {\n",
    "        'Jitter(%)': jitter_percent,\n",
    "        'Jitter(Abs)': jitter_abs,\n",
    "        'Jitter:RAP': jitter_rap,\n",
    "        'Jitter:PPQ5': jitter_ppq5,\n",
    "        'Jitter:DDP': jitter_ddp,\n",
    "        'Shimmer': shimmer,\n",
    "        'Shimmer(dB)': shimmer_db,\n",
    "        'Shimmer:APQ3': shimmer_apq3,\n",
    "        'Shimmer:APQ5': shimmer_apq5,\n",
    "        'Shimmer:APQ11': shimmer_apq11,\n",
    "        'Shimmer:DDA': shimmer_dda,\n",
    "        'NHR': nhr,\n",
    "        'HNR': hnr,\n",
    "        'RPDE': rpde,\n",
    "        'DFA': dfa,\n",
    "        'PPE': ppe\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "audio_file = \"amir.wav\"\n",
    "features = extract_features(audio_file)\n",
    "print(features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
